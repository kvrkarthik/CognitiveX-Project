# Hugging Face Configuration  
# Get this from: https://huggingface.co/settings/tokens
# Note: Many IBM models on Hugging Face don't require API keys for inference
HUGGING_FACE_API_KEY=your_hugging_face_token_here

# FastAPI Configuration
FASTAPI_HOST=0.0.0.0
FASTAPI_PORT=8000

# IBM Models Configuration (via Hugging Face)
# These models don't require API keys for basic inference
IBM_GRANITE_MODEL=ibm-granite/granite-3.0-2b-instruct
IBM_WATSONX_MODEL=ibm/granite-7b-instruct
IBM_MEDICAL_MODEL=ibm-granite/granite-3.0-8b-instruct

# Instructions:
# 1. Copy this file to .env and replace 'your_hugging_face_token_here' with your actual HF token
# 2. IBM models on Hugging Face can often be used without API keys for inference
# 3. For production use, consider getting a Hugging Face Pro account for faster inference
